{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. To read the content of the nlp_input.text file and encode the content to UTF8 \n",
    "with open('nlp_input.txt', encoding='utf8', errors='ignore') as f:\n",
    "    nlp_q7_text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression\n",
      "analysis\n",
      "is\n",
      "a\n",
      "statistical\n",
      "technique\n",
      "that\n",
      "models\n",
      "and\n",
      "approximates\n",
      "the\n",
      "relationship\n",
      "between\n",
      "a\n",
      "dependent\n",
      "and\n",
      "one\n",
      "or\n",
      "more\n",
      "independent\n",
      "variables\n",
      ".\n",
      "This\n",
      "article\n",
      "will\n",
      "quickly\n",
      "introduce\n",
      "three\n",
      "commonly\n",
      "used\n",
      "regression\n",
      "models\n",
      "using\n",
      "R\n",
      "and\n",
      "the\n",
      "Boston\n",
      "housing\n",
      "data-set\n",
      ":\n",
      "Ridge\n",
      ",\n",
      "Lasso\n",
      ",\n",
      "and\n",
      "Elastic\n",
      "Net\n",
      ".\n",
      "First\n",
      "we\n",
      "need\n",
      "to\n",
      "understand\n",
      "the\n",
      "basics\n",
      "of\n",
      "regression\n",
      "and\n",
      "what\n",
      "parameters\n",
      "of\n",
      "the\n",
      "equation\n",
      "are\n",
      "changed\n",
      "when\n",
      "using\n",
      "a\n",
      "specific\n",
      "model\n",
      ".\n",
      "Simple\n",
      "linear\n",
      "regression\n",
      ",\n",
      "also\n",
      "known\n",
      "as\n",
      "ordinary\n",
      "least\n",
      "squares\n",
      "(\n",
      "OLS\n",
      ")\n",
      "attempts\n",
      "to\n",
      "minimize\n",
      "the\n",
      "sum\n",
      "of\n",
      "error\n",
      "squared\n",
      ".\n",
      "The\n",
      "error\n",
      "in\n",
      "this\n",
      "case\n",
      "is\n",
      "the\n",
      "difference\n",
      "between\n",
      "the\n",
      "actual\n",
      "data\n",
      "point\n",
      "and\n",
      "its\n",
      "predicted\n",
      "value\n",
      ".\n",
      "Visualization\n",
      "of\n",
      "the\n",
      "squared\n",
      "error\n",
      "(\n",
      "from\n",
      "Setosa.io\n",
      ")\n",
      "The\n",
      "equation\n",
      "for\n",
      "this\n",
      "model\n",
      "is\n",
      "referred\n",
      "to\n",
      "as\n",
      "the\n",
      "cost\n",
      "function\n",
      "and\n",
      "is\n",
      "a\n",
      "way\n",
      "to\n",
      "find\n",
      "the\n",
      "optimal\n",
      "error\n",
      "by\n",
      "minimizing\n",
      "and\n",
      "measuring\n",
      "it\n",
      ".\n",
      "The\n",
      "gradient\n",
      "descent\n",
      "algorithm\n",
      "is\n",
      "used\n",
      "to\n",
      "find\n",
      "the\n",
      "optimal\n",
      "cost\n",
      "function\n",
      "by\n",
      "going\n",
      "over\n",
      "a\n",
      "number\n",
      "of\n",
      "iterations\n",
      ".\n",
      "But\n",
      "the\n",
      "data\n",
      "we\n",
      "need\n",
      "to\n",
      "define\n",
      "and\n",
      "analyze\n",
      "is\n",
      "not\n",
      "always\n",
      "so\n",
      "easy\n",
      "to\n",
      "characterize\n",
      "with\n",
      "the\n",
      "base\n",
      "OLS\n",
      "model\n",
      ".\n",
      "Equation\n",
      "for\n",
      "least\n",
      "ordinary\n",
      "squares\n",
      "One\n",
      "situation\n",
      "is\n",
      "the\n",
      "data\n",
      "showing\n",
      "multi-collinearity\n",
      ",\n",
      "this\n",
      "is\n",
      "when\n",
      "predictor\n",
      "variables\n",
      "are\n",
      "correlated\n",
      "to\n",
      "each\n",
      "other\n",
      "and\n",
      "to\n",
      "the\n",
      "response\n",
      "variable\n",
      ".\n",
      "To\n",
      "picture\n",
      "this\n",
      "lets\n",
      "say\n",
      "were\n",
      "doing\n",
      "a\n",
      "study\n",
      "that\n",
      "looks\n",
      "at\n",
      "a\n",
      "response\n",
      "variable\n",
      "?\n",
      "?\n",
      "patient\n",
      "weight\n",
      ",\n",
      "and\n",
      "our\n",
      "predictor\n",
      "variables\n",
      "would\n",
      "be\n",
      "height\n",
      ",\n",
      "sex\n",
      ",\n",
      "and\n",
      "diet\n",
      ".\n",
      "The\n",
      "problem\n",
      "here\n",
      "is\n",
      "that\n",
      "height\n",
      "and\n",
      "sex\n",
      "are\n",
      "also\n",
      "correlated\n",
      "and\n",
      "can\n",
      "inflate\n",
      "the\n",
      "standard\n",
      "error\n",
      "of\n",
      "their\n",
      "coefficients\n",
      "which\n",
      "may\n",
      "make\n",
      "them\n",
      "seem\n",
      "statistically\n",
      "insignificant\n",
      ".\n",
      "To\n",
      "produce\n",
      "a\n",
      "more\n",
      "accurate\n",
      "model\n",
      "of\n",
      "complex\n",
      "data\n",
      "we\n",
      "can\n",
      "add\n",
      "a\n",
      "penalty\n",
      "term\n",
      "to\n",
      "the\n",
      "OLS\n",
      "equation\n",
      ".\n",
      "A\n",
      "penalty\n",
      "adds\n",
      "a\n",
      "bias\n",
      "towards\n",
      "certain\n",
      "values\n",
      ".\n",
      "These\n",
      "are\n",
      "known\n",
      "as\n",
      "L1\n",
      "regularization\n",
      "(\n",
      "Lasso\n",
      "regression\n",
      ")\n",
      "and\n",
      "L2\n",
      "regularization\n",
      "(\n",
      "ridge\n",
      "regression\n",
      ")\n",
      ".The\n",
      "best\n",
      "model\n",
      "we\n",
      "can\n",
      "hope\n",
      "to\n",
      "come\n",
      "up\n",
      "with\n",
      "minimizes\n",
      "both\n",
      "the\n",
      "bias\n",
      "and\n",
      "the\n",
      "variance\n",
      ":\n",
      "Ridge\n",
      "regression\n",
      "uses\n",
      "L2\n",
      "regularization\n",
      "which\n",
      "adds\n",
      "the\n",
      "following\n",
      "penalty\n",
      "term\n",
      "to\n",
      "the\n",
      "OLS\n",
      "equation\n",
      ".\n",
      "L2\n",
      "regularization\n",
      "penalty\n",
      "term\n",
      "The\n",
      "L2\n",
      "term\n",
      "is\n",
      "equal\n",
      "to\n",
      "the\n",
      "square\n",
      "of\n",
      "the\n",
      "magnitude\n",
      "of\n",
      "the\n",
      "coefficients\n",
      ".\n",
      "In\n",
      "this\n",
      "case\n",
      "if\n",
      "lambda\n",
      "(\n",
      "?\n",
      ")\n",
      "is\n",
      "zero\n",
      "then\n",
      "the\n",
      "equation\n",
      "is\n",
      "the\n",
      "basic\n",
      "OLS\n",
      "but\n",
      "if\n",
      "it\n",
      "is\n",
      "greater\n",
      "than\n",
      "zero\n",
      "then\n",
      "we\n",
      "add\n",
      "a\n",
      "constraint\n",
      "to\n",
      "the\n",
      "coefficients\n",
      ".\n",
      "This\n",
      "constraint\n",
      "results\n",
      "in\n",
      "minimized\n",
      "coefficients\n",
      "(\n",
      "aka\n",
      "shrinkage\n",
      ")\n",
      "that\n",
      "trend\n",
      "towards\n",
      "zero\n",
      "the\n",
      "larger\n",
      "the\n",
      "value\n",
      "of\n",
      "lambda\n",
      ".\n",
      "Shrinking\n",
      "the\n",
      "coefficients\n",
      "leads\n",
      "to\n",
      "a\n",
      "lower\n",
      "variance\n",
      "and\n",
      "in\n",
      "turn\n",
      "a\n",
      "lower\n",
      "error\n",
      "value\n",
      ".\n",
      "Therefore\n",
      "Ridge\n",
      "regression\n",
      "decreases\n",
      "the\n",
      "complexity\n",
      "of\n",
      "a\n",
      "model\n",
      "but\n",
      "does\n",
      "not\n",
      "reduce\n",
      "the\n",
      "number\n",
      "of\n",
      "variables\n",
      ",\n",
      "it\n",
      "rather\n",
      "just\n",
      "shrinks\n",
      "their\n",
      "effect\n",
      ".\n",
      "Lasso\n",
      "regression\n",
      "Lasso\n",
      "regression\n",
      "uses\n",
      "the\n",
      "L1\n",
      "penalty\n",
      "term\n",
      "and\n",
      "stands\n",
      "for\n",
      "Least\n",
      "Absolute\n",
      "Shrinkage\n",
      "and\n",
      "Selection\n",
      "Operator\n",
      ".\n",
      "The\n",
      "penalty\n",
      "applied\n",
      "for\n",
      "L2\n",
      "is\n",
      "equal\n",
      "to\n",
      "the\n",
      "absolute\n",
      "value\n",
      "of\n",
      "the\n",
      "magnitude\n",
      "of\n",
      "the\n",
      "coefficients\n",
      ":\n",
      "L1\n",
      "regularization\n",
      "penalty\n",
      "term\n",
      "Similar\n",
      "to\n",
      "ridge\n",
      "regression\n",
      ",\n",
      "a\n",
      "lambda\n",
      "value\n",
      "of\n",
      "zero\n",
      "spits\n",
      "out\n",
      "the\n",
      "basic\n",
      "OLS\n",
      "equation\n",
      ",\n",
      "however\n",
      "given\n",
      "a\n",
      "suitable\n",
      "lambda\n",
      "value\n",
      "lasso\n",
      "regression\n",
      "can\n",
      "drive\n",
      "some\n",
      "coefficients\n",
      "to\n",
      "zero\n",
      ".\n",
      "The\n",
      "larger\n",
      "the\n",
      "value\n",
      "of\n",
      "lambda\n",
      "the\n",
      "more\n",
      "features\n",
      "are\n",
      "shrunk\n",
      "to\n",
      "zero\n",
      ".\n",
      "This\n",
      "can\n",
      "eliminate\n",
      "some\n",
      "features\n",
      "entirely\n",
      "and\n",
      "give\n",
      "us\n",
      "a\n",
      "subset\n",
      "of\n",
      "predictors\n",
      "that\n",
      "helps\n",
      "mitigate\n",
      "multi-collinearity\n",
      "and\n",
      "model\n",
      "complexity\n",
      ".\n",
      "Predictors\n",
      "not\n",
      "shrunk\n",
      "towards\n",
      "zero\n",
      "signify\n",
      "that\n",
      "they\n",
      "are\n",
      "important\n",
      "and\n",
      "thus\n",
      "L1\n",
      "regularization\n",
      "allows\n",
      "for\n",
      "feature\n",
      "selection\n",
      "(\n",
      "sparse\n",
      "selection\n",
      ")\n",
      ".\n",
      "A\n",
      "third\n",
      "commonly\n",
      "used\n",
      "model\n",
      "of\n",
      "regression\n",
      "is\n",
      "the\n",
      "Elastic\n",
      "Net\n",
      "which\n",
      "incorporates\n",
      "penalties\n",
      "from\n",
      "both\n",
      "L1\n",
      "and\n",
      "L2\n",
      "regularization\n",
      ":\n",
      "In\n",
      "addition\n",
      "to\n",
      "setting\n",
      "and\n",
      "choosing\n",
      "a\n",
      "lambda\n",
      "value\n",
      "elastic\n",
      "net\n",
      "also\n",
      "allows\n",
      "us\n",
      "to\n",
      "tune\n",
      "the\n",
      "alpha\n",
      "parameter\n",
      "where\n",
      "?\n",
      "?\n",
      "=\n",
      "0\n",
      "corresponds\n",
      "to\n",
      "ridge\n",
      "and\n",
      "?\n",
      "?\n",
      "=\n",
      "1\n",
      "to\n",
      "lasso\n",
      ".\n",
      "Simply\n",
      "put\n",
      ",\n",
      "if\n",
      "you\n",
      "plug\n",
      "in\n",
      "0\n",
      "for\n",
      "alpha\n",
      ",\n",
      "the\n",
      "penalty\n",
      "function\n",
      "reduces\n",
      "to\n",
      "the\n",
      "L1\n",
      "(\n",
      "ridge\n",
      ")\n",
      "term\n",
      "and\n",
      "if\n",
      "we\n",
      "set\n",
      "alpha\n",
      "to\n",
      "1\n",
      "we\n",
      "get\n",
      "the\n",
      "L2\n",
      "(\n",
      "lasso\n",
      ")\n",
      "term\n",
      ".\n",
      "Therefore\n",
      "we\n",
      "can\n",
      "choose\n",
      "an\n",
      "alpha\n",
      "value\n",
      "between\n",
      "0\n",
      "and\n",
      "1\n",
      "to\n",
      "optimize\n",
      "the\n",
      "elastic\n",
      "net\n",
      ".\n",
      "Effectively\n",
      "this\n",
      "will\n",
      "shrink\n",
      "some\n",
      "coefficients\n",
      "and\n",
      "set\n",
      "some\n",
      "to\n",
      "0\n",
      "for\n",
      "sparse\n",
      "selection\n",
      ".\n",
      "As\n",
      "we\n",
      "mentioned\n",
      "in\n",
      "the\n",
      "previous\n",
      "sections\n",
      ",\n",
      "lambda\n",
      "values\n",
      "have\n",
      "a\n",
      "large\n",
      "effect\n",
      "on\n",
      "coefficients\n",
      "so\n",
      "now\n",
      "we\n",
      "will\n",
      "compute\n",
      "and\n",
      "chose\n",
      "a\n",
      "suitable\n",
      "one\n",
      ".\n",
      "Here\n",
      "we\n",
      "perform\n",
      "a\n",
      "cross\n",
      "validation\n",
      "and\n",
      "take\n",
      "a\n",
      "peek\n",
      "at\n",
      "the\n",
      "lambda\n",
      "value\n",
      "corresponding\n",
      "to\n",
      "the\n",
      "lowest\n",
      "prediction\n",
      "error\n",
      "before\n",
      "fitting\n",
      "the\n",
      "data\n",
      "to\n",
      "the\n",
      "model\n",
      "and\n",
      "viewing\n",
      "the\n",
      "coefficients\n",
      ".\n",
      "We\n",
      "can\n",
      "see\n",
      "here\n",
      "that\n",
      "certain\n",
      "coefficients\n",
      "have\n",
      "been\n",
      "pushed\n",
      "towards\n",
      "zero\n",
      "and\n",
      "minimized\n",
      "while\n",
      "RM\n",
      "(\n",
      "number\n",
      "of\n",
      "rooms\n",
      ")\n",
      "has\n",
      "a\n",
      "significantly\n",
      "higher\n",
      "weight\n",
      "than\n",
      "the\n",
      "rest\n",
      "Performing\n",
      "Lasso\n",
      "regression\n",
      "The\n",
      "steps\n",
      "will\n",
      "be\n",
      "identical\n",
      "to\n",
      "what\n",
      "we\n",
      "have\n",
      "done\n",
      "for\n",
      "ridge\n",
      "regression\n",
      ".\n",
      "The\n",
      "value\n",
      "of\n",
      "alpha\n",
      "is\n",
      "the\n",
      "only\n",
      "change\n",
      "here\n",
      "(\n",
      "remember\n",
      "?\n",
      "?\n",
      "=\n",
      "1\n",
      "denotes\n",
      "lasso\n",
      ")\n",
      "Performing\n",
      "Elastic\n",
      "Net\n",
      "regression\n",
      "Performing\n",
      "Elastic\n",
      "Net\n",
      "requires\n",
      "us\n",
      "to\n",
      "tune\n",
      "parameters\n",
      "to\n",
      "identify\n",
      "the\n",
      "best\n",
      "alpha\n",
      "and\n",
      "lambda\n",
      "values\n",
      "and\n",
      "for\n",
      "this\n",
      "we\n",
      "need\n",
      "to\n",
      "use\n",
      "the\n",
      "caret\n",
      "package\n",
      ".\n",
      "We\n",
      "will\n",
      "tune\n",
      "the\n",
      "model\n",
      "by\n",
      "iterating\n",
      "over\n",
      "a\n",
      "number\n",
      "of\n",
      "alpha\n",
      "and\n",
      "lambda\n",
      "pairs\n",
      "and\n",
      "we\n",
      "can\n",
      "see\n",
      "which\n",
      "pair\n",
      "has\n",
      "the\n",
      "lowest\n",
      "associated\n",
      "error\n",
      ".\n",
      "We\n",
      "can\n",
      "see\n",
      "that\n",
      "the\n",
      "R\n",
      "mean-squared\n",
      "values\n",
      "using\n",
      "all\n",
      "three\n",
      "models\n",
      "were\n",
      "very\n",
      "close\n",
      "to\n",
      "each\n",
      "other\n",
      ",\n",
      "but\n",
      "both\n",
      "did\n",
      "marginally\n",
      "perform\n",
      "better\n",
      "than\n",
      "ridge\n",
      "regression\n",
      "(\n",
      "Lasso\n",
      "having\n",
      "done\n",
      "best\n",
      ")\n",
      ".\n",
      "Lasso\n",
      "regression\n",
      "also\n",
      "showed\n",
      "the\n",
      "highest\n",
      "R\n",
      "value\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#B. To Tokenize the text into words and apply lemmatization technique on each word\n",
    "\n",
    "\n",
    "\n",
    "#First, To perform Tokenization on the nlp_input_text, we will use words Tokenization:\n",
    "q7wordToken = nltk.word_tokenize(nlp_q7_text)\n",
    "for word in q7wordToken:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Regression', 'analysis', 'is', 'a', 'statistical', 'technique', 'that', 'models', 'and', 'approximates', 'the', 'relationship', 'between', 'a', 'dependent', 'and', 'one', 'or', 'more', 'independent', 'variables', '.', 'This', 'article', 'will', 'quickly', 'introduce', 'three', 'commonly', 'used', 'regression', 'models', 'using', 'R', 'and', 'the', 'Boston', 'housing', 'data-set', ':', 'Ridge', ',', 'Lasso', ',', 'and', 'Elastic', 'Net', '.', 'First', 'we', 'need', 'to', 'understand', 'the', 'basics', 'of', 'regression', 'and', 'what', 'parameters', 'of', 'the', 'equation', 'are', 'changed', 'when', 'using', 'a', 'specific', 'model', '.', 'Simple', 'linear', 'regression', ',', 'also', 'known', 'as', 'ordinary', 'least', 'squares', '(', 'OLS', ')', 'attempts', 'to', 'minimize', 'the', 'sum', 'of', 'error', 'squared', '.', 'The', 'error', 'in', 'this', 'case', 'is', 'the', 'difference', 'between', 'the', 'actual', 'data', 'point', 'and', 'its', 'predicted', 'value', '.', 'Visualization', 'of', 'the', 'squared', 'error', '(', 'from', 'Setosa.io', ')', 'The', 'equation', 'for', 'this', 'model', 'is', 'referred', 'to', 'as', 'the', 'cost', 'function', 'and', 'is', 'a', 'way', 'to', 'find', 'the', 'optimal', 'error', 'by', 'minimizing', 'and', 'measuring', 'it', '.', 'The', 'gradient', 'descent', 'algorithm', 'is', 'used', 'to', 'find', 'the', 'optimal', 'cost', 'function', 'by', 'going', 'over', 'a', 'number', 'of', 'iterations', '.', 'But', 'the', 'data', 'we', 'need', 'to', 'define', 'and', 'analyze', 'is', 'not', 'always', 'so', 'easy', 'to', 'characterize', 'with', 'the', 'base', 'OLS', 'model', '.', 'Equation', 'for', 'least', 'ordinary', 'squares', 'One', 'situation', 'is', 'the', 'data', 'showing', 'multi-collinearity', ',', 'this', 'is', 'when', 'predictor', 'variables', 'are', 'correlated', 'to', 'each', 'other', 'and', 'to', 'the', 'response', 'variable', '.', 'To', 'picture', 'this', 'lets', 'say', 'were', 'doing', 'a', 'study', 'that', 'looks', 'at', 'a', 'response', 'variable', '?', '?', 'patient', 'weight', ',', 'and', 'our', 'predictor', 'variables', 'would', 'be', 'height', ',', 'sex', ',', 'and', 'diet', '.', 'The', 'problem', 'here', 'is', 'that', 'height', 'and', 'sex', 'are', 'also', 'correlated', 'and', 'can', 'inflate', 'the', 'standard', 'error', 'of', 'their', 'coefficients', 'which', 'may', 'make', 'them', 'seem', 'statistically', 'insignificant', '.', 'To', 'produce', 'a', 'more', 'accurate', 'model', 'of', 'complex', 'data', 'we', 'can', 'add', 'a', 'penalty', 'term', 'to', 'the', 'OLS', 'equation', '.', 'A', 'penalty', 'adds', 'a', 'bias', 'towards', 'certain', 'values', '.', 'These', 'are', 'known', 'as', 'L1', 'regularization', '(', 'Lasso', 'regression', ')', 'and', 'L2', 'regularization', '(', 'ridge', 'regression', ')', '.The', 'best', 'model', 'we', 'can', 'hope', 'to', 'come', 'up', 'with', 'minimizes', 'both', 'the', 'bias', 'and', 'the', 'variance', ':', 'Ridge', 'regression', 'uses', 'L2', 'regularization', 'which', 'adds', 'the', 'following', 'penalty', 'term', 'to', 'the', 'OLS', 'equation', '.', 'L2', 'regularization', 'penalty', 'term', 'The', 'L2', 'term', 'is', 'equal', 'to', 'the', 'square', 'of', 'the', 'magnitude', 'of', 'the', 'coefficients', '.', 'In', 'this', 'case', 'if', 'lambda', '(', '?', ')', 'is', 'zero', 'then', 'the', 'equation', 'is', 'the', 'basic', 'OLS', 'but', 'if', 'it', 'is', 'greater', 'than', 'zero', 'then', 'we', 'add', 'a', 'constraint', 'to', 'the', 'coefficients', '.', 'This', 'constraint', 'results', 'in', 'minimized', 'coefficients', '(', 'aka', 'shrinkage', ')', 'that', 'trend', 'towards', 'zero', 'the', 'larger', 'the', 'value', 'of', 'lambda', '.', 'Shrinking', 'the', 'coefficients', 'leads', 'to', 'a', 'lower', 'variance', 'and', 'in', 'turn', 'a', 'lower', 'error', 'value', '.', 'Therefore', 'Ridge', 'regression', 'decreases', 'the', 'complexity', 'of', 'a', 'model', 'but', 'does', 'not', 'reduce', 'the', 'number', 'of', 'variables', ',', 'it', 'rather', 'just', 'shrinks', 'their', 'effect', '.', 'Lasso', 'regression', 'Lasso', 'regression', 'uses', 'the', 'L1', 'penalty', 'term', 'and', 'stands', 'for', 'Least', 'Absolute', 'Shrinkage', 'and', 'Selection', 'Operator', '.', 'The', 'penalty', 'applied', 'for', 'L2', 'is', 'equal', 'to', 'the', 'absolute', 'value', 'of', 'the', 'magnitude', 'of', 'the', 'coefficients', ':', 'L1', 'regularization', 'penalty', 'term', 'Similar', 'to', 'ridge', 'regression', ',', 'a', 'lambda', 'value', 'of', 'zero', 'spits', 'out', 'the', 'basic', 'OLS', 'equation', ',', 'however', 'given', 'a', 'suitable', 'lambda', 'value', 'lasso', 'regression', 'can', 'drive', 'some', 'coefficients', 'to', 'zero', '.', 'The', 'larger', 'the', 'value', 'of', 'lambda', 'the', 'more', 'features', 'are', 'shrunk', 'to', 'zero', '.', 'This', 'can', 'eliminate', 'some', 'features', 'entirely', 'and', 'give', 'us', 'a', 'subset', 'of', 'predictors', 'that', 'helps', 'mitigate', 'multi-collinearity', 'and', 'model', 'complexity', '.', 'Predictors', 'not', 'shrunk', 'towards', 'zero', 'signify', 'that', 'they', 'are', 'important', 'and', 'thus', 'L1', 'regularization', 'allows', 'for', 'feature', 'selection', '(', 'sparse', 'selection', ')', '.', 'A', 'third', 'commonly', 'used', 'model', 'of', 'regression', 'is', 'the', 'Elastic', 'Net', 'which', 'incorporates', 'penalties', 'from', 'both', 'L1', 'and', 'L2', 'regularization', ':', 'In', 'addition', 'to', 'setting', 'and', 'choosing', 'a', 'lambda', 'value', 'elastic', 'net', 'also', 'allows', 'us', 'to', 'tune', 'the', 'alpha', 'parameter', 'where', '?', '?', '=', '0', 'corresponds', 'to', 'ridge', 'and', '?', '?', '=', '1', 'to', 'lasso', '.', 'Simply', 'put', ',', 'if', 'you', 'plug', 'in', '0', 'for', 'alpha', ',', 'the', 'penalty', 'function', 'reduces', 'to', 'the', 'L1', '(', 'ridge', ')', 'term', 'and', 'if', 'we', 'set', 'alpha', 'to', '1', 'we', 'get', 'the', 'L2', '(', 'lasso', ')', 'term', '.', 'Therefore', 'we', 'can', 'choose', 'an', 'alpha', 'value', 'between', '0', 'and', '1', 'to', 'optimize', 'the', 'elastic', 'net', '.', 'Effectively', 'this', 'will', 'shrink', 'some', 'coefficients', 'and', 'set', 'some', 'to', '0', 'for', 'sparse', 'selection', '.', 'As', 'we', 'mentioned', 'in', 'the', 'previous', 'sections', ',', 'lambda', 'values', 'have', 'a', 'large', 'effect', 'on', 'coefficients', 'so', 'now', 'we', 'will', 'compute', 'and', 'chose', 'a', 'suitable', 'one', '.', 'Here', 'we', 'perform', 'a', 'cross', 'validation', 'and', 'take', 'a', 'peek', 'at', 'the', 'lambda', 'value', 'corresponding', 'to', 'the', 'lowest', 'prediction', 'error', 'before', 'fitting', 'the', 'data', 'to', 'the', 'model', 'and', 'viewing', 'the', 'coefficients', '.', 'We', 'can', 'see', 'here', 'that', 'certain', 'coefficients', 'have', 'been', 'pushed', 'towards', 'zero', 'and', 'minimized', 'while', 'RM', '(', 'number', 'of', 'rooms', ')', 'has', 'a', 'significantly', 'higher', 'weight', 'than', 'the', 'rest', 'Performing', 'Lasso', 'regression', 'The', 'steps', 'will', 'be', 'identical', 'to', 'what', 'we', 'have', 'done', 'for', 'ridge', 'regression', '.', 'The', 'value', 'of', 'alpha', 'is', 'the', 'only', 'change', 'here', '(', 'remember', '?', '?', '=', '1', 'denotes', 'lasso', ')', 'Performing', 'Elastic', 'Net', 'regression', 'Performing', 'Elastic', 'Net', 'requires', 'us', 'to', 'tune', 'parameters', 'to', 'identify', 'the', 'best', 'alpha', 'and', 'lambda', 'values', 'and', 'for', 'this', 'we', 'need', 'to', 'use', 'the', 'caret', 'package', '.', 'We', 'will', 'tune', 'the', 'model', 'by', 'iterating', 'over', 'a', 'number', 'of', 'alpha', 'and', 'lambda', 'pairs', 'and', 'we', 'can', 'see', 'which', 'pair', 'has', 'the', 'lowest', 'associated', 'error', '.', 'We', 'can', 'see', 'that', 'the', 'R', 'mean-squared', 'values', 'using', 'all', 'three', 'models', 'were', 'very', 'close', 'to', 'each', 'other', ',', 'but', 'both', 'did', 'marginally', 'perform', 'better', 'than', 'ridge', 'regression', '(', 'Lasso', 'having', 'done', 'best', ')', '.', 'Lasso', 'regression', 'also', 'showed', 'the', 'highest', 'R', 'value', '.']\n"
     ]
    }
   ],
   "source": [
    "#To apply lemmatization technique on each word\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "q7_lemmatization = WordNetLemmatizer()\n",
    "q7_lemmatization_result = q7_lemmatization.lemmatize(str(q7wordToken))\n",
    "print(q7_lemmatization_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Regression', 'analysis', 'is'), ('analysis', 'is', 'a'), ('is', 'a', 'statistical'), ('a', 'statistical', 'technique'), ('statistical', 'technique', 'that'), ('technique', 'that', 'models'), ('that', 'models', 'and'), ('models', 'and', 'approximates'), ('and', 'approximates', 'the'), ('approximates', 'the', 'relationship'), ('the', 'relationship', 'between'), ('relationship', 'between', 'a'), ('between', 'a', 'dependent'), ('a', 'dependent', 'and'), ('dependent', 'and', 'one'), ('and', 'one', 'or'), ('one', 'or', 'more'), ('or', 'more', 'independent'), ('more', 'independent', 'variables'), ('independent', 'variables', '.'), ('variables', '.', 'This'), ('.', 'This', 'article'), ('This', 'article', 'will'), ('article', 'will', 'quickly'), ('will', 'quickly', 'introduce'), ('quickly', 'introduce', 'three'), ('introduce', 'three', 'commonly'), ('three', 'commonly', 'used'), ('commonly', 'used', 'regression'), ('used', 'regression', 'models'), ('regression', 'models', 'using'), ('models', 'using', 'R'), ('using', 'R', 'and'), ('R', 'and', 'the'), ('and', 'the', 'Boston'), ('the', 'Boston', 'housing'), ('Boston', 'housing', 'data-set'), ('housing', 'data-set', ':'), ('data-set', ':', 'Ridge'), (':', 'Ridge', ','), ('Ridge', ',', 'Lasso'), (',', 'Lasso', ','), ('Lasso', ',', 'and'), (',', 'and', 'Elastic'), ('and', 'Elastic', 'Net'), ('Elastic', 'Net', '.'), ('Net', '.', 'First'), ('.', 'First', 'we'), ('First', 'we', 'need'), ('we', 'need', 'to'), ('need', 'to', 'understand'), ('to', 'understand', 'the'), ('understand', 'the', 'basics'), ('the', 'basics', 'of'), ('basics', 'of', 'regression'), ('of', 'regression', 'and'), ('regression', 'and', 'what'), ('and', 'what', 'parameters'), ('what', 'parameters', 'of'), ('parameters', 'of', 'the'), ('of', 'the', 'equation'), ('the', 'equation', 'are'), ('equation', 'are', 'changed'), ('are', 'changed', 'when'), ('changed', 'when', 'using'), ('when', 'using', 'a'), ('using', 'a', 'specific'), ('a', 'specific', 'model'), ('specific', 'model', '.'), ('model', '.', 'Simple'), ('.', 'Simple', 'linear'), ('Simple', 'linear', 'regression'), ('linear', 'regression', ','), ('regression', ',', 'also'), (',', 'also', 'known'), ('also', 'known', 'as'), ('known', 'as', 'ordinary'), ('as', 'ordinary', 'least'), ('ordinary', 'least', 'squares'), ('least', 'squares', '('), ('squares', '(', 'OLS'), ('(', 'OLS', ')'), ('OLS', ')', 'attempts'), (')', 'attempts', 'to'), ('attempts', 'to', 'minimize'), ('to', 'minimize', 'the'), ('minimize', 'the', 'sum'), ('the', 'sum', 'of'), ('sum', 'of', 'error'), ('of', 'error', 'squared'), ('error', 'squared', '.'), ('squared', '.', 'The'), ('.', 'The', 'error'), ('The', 'error', 'in'), ('error', 'in', 'this'), ('in', 'this', 'case'), ('this', 'case', 'is'), ('case', 'is', 'the'), ('is', 'the', 'difference'), ('the', 'difference', 'between'), ('difference', 'between', 'the'), ('between', 'the', 'actual'), ('the', 'actual', 'data'), ('actual', 'data', 'point'), ('data', 'point', 'and'), ('point', 'and', 'its'), ('and', 'its', 'predicted'), ('its', 'predicted', 'value'), ('predicted', 'value', '.'), ('value', '.', 'Visualization'), ('.', 'Visualization', 'of'), ('Visualization', 'of', 'the'), ('of', 'the', 'squared'), ('the', 'squared', 'error'), ('squared', 'error', '('), ('error', '(', 'from'), ('(', 'from', 'Setosa.io'), ('from', 'Setosa.io', ')'), ('Setosa.io', ')', 'The'), (')', 'The', 'equation'), ('The', 'equation', 'for'), ('equation', 'for', 'this'), ('for', 'this', 'model'), ('this', 'model', 'is'), ('model', 'is', 'referred'), ('is', 'referred', 'to'), ('referred', 'to', 'as'), ('to', 'as', 'the'), ('as', 'the', 'cost'), ('the', 'cost', 'function'), ('cost', 'function', 'and'), ('function', 'and', 'is'), ('and', 'is', 'a'), ('is', 'a', 'way'), ('a', 'way', 'to'), ('way', 'to', 'find'), ('to', 'find', 'the'), ('find', 'the', 'optimal'), ('the', 'optimal', 'error'), ('optimal', 'error', 'by'), ('error', 'by', 'minimizing'), ('by', 'minimizing', 'and'), ('minimizing', 'and', 'measuring'), ('and', 'measuring', 'it'), ('measuring', 'it', '.'), ('it', '.', 'The'), ('.', 'The', 'gradient'), ('The', 'gradient', 'descent'), ('gradient', 'descent', 'algorithm'), ('descent', 'algorithm', 'is'), ('algorithm', 'is', 'used'), ('is', 'used', 'to'), ('used', 'to', 'find'), ('to', 'find', 'the'), ('find', 'the', 'optimal'), ('the', 'optimal', 'cost'), ('optimal', 'cost', 'function'), ('cost', 'function', 'by'), ('function', 'by', 'going'), ('by', 'going', 'over'), ('going', 'over', 'a'), ('over', 'a', 'number'), ('a', 'number', 'of'), ('number', 'of', 'iterations'), ('of', 'iterations', '.'), ('iterations', '.', 'But'), ('.', 'But', 'the'), ('But', 'the', 'data'), ('the', 'data', 'we'), ('data', 'we', 'need'), ('we', 'need', 'to'), ('need', 'to', 'define'), ('to', 'define', 'and'), ('define', 'and', 'analyze'), ('and', 'analyze', 'is'), ('analyze', 'is', 'not'), ('is', 'not', 'always'), ('not', 'always', 'so'), ('always', 'so', 'easy'), ('so', 'easy', 'to'), ('easy', 'to', 'characterize'), ('to', 'characterize', 'with'), ('characterize', 'with', 'the'), ('with', 'the', 'base'), ('the', 'base', 'OLS'), ('base', 'OLS', 'model'), ('OLS', 'model', '.'), ('model', '.', 'Equation'), ('.', 'Equation', 'for'), ('Equation', 'for', 'least'), ('for', 'least', 'ordinary'), ('least', 'ordinary', 'squares'), ('ordinary', 'squares', 'One'), ('squares', 'One', 'situation'), ('One', 'situation', 'is'), ('situation', 'is', 'the'), ('is', 'the', 'data'), ('the', 'data', 'showing'), ('data', 'showing', 'multi-collinearity'), ('showing', 'multi-collinearity', ','), ('multi-collinearity', ',', 'this'), (',', 'this', 'is'), ('this', 'is', 'when'), ('is', 'when', 'predictor'), ('when', 'predictor', 'variables'), ('predictor', 'variables', 'are'), ('variables', 'are', 'correlated'), ('are', 'correlated', 'to'), ('correlated', 'to', 'each'), ('to', 'each', 'other'), ('each', 'other', 'and'), ('other', 'and', 'to'), ('and', 'to', 'the'), ('to', 'the', 'response'), ('the', 'response', 'variable'), ('response', 'variable', '.'), ('variable', '.', 'To'), ('.', 'To', 'picture'), ('To', 'picture', 'this'), ('picture', 'this', 'lets'), ('this', 'lets', 'say'), ('lets', 'say', 'were'), ('say', 'were', 'doing'), ('were', 'doing', 'a'), ('doing', 'a', 'study'), ('a', 'study', 'that'), ('study', 'that', 'looks'), ('that', 'looks', 'at'), ('looks', 'at', 'a'), ('at', 'a', 'response'), ('a', 'response', 'variable'), ('response', 'variable', '?'), ('variable', '?', '?'), ('?', '?', 'patient'), ('?', 'patient', 'weight'), ('patient', 'weight', ','), ('weight', ',', 'and'), (',', 'and', 'our'), ('and', 'our', 'predictor'), ('our', 'predictor', 'variables'), ('predictor', 'variables', 'would'), ('variables', 'would', 'be'), ('would', 'be', 'height'), ('be', 'height', ','), ('height', ',', 'sex'), (',', 'sex', ','), ('sex', ',', 'and'), (',', 'and', 'diet'), ('and', 'diet', '.'), ('diet', '.', 'The'), ('.', 'The', 'problem'), ('The', 'problem', 'here'), ('problem', 'here', 'is'), ('here', 'is', 'that'), ('is', 'that', 'height'), ('that', 'height', 'and'), ('height', 'and', 'sex'), ('and', 'sex', 'are'), ('sex', 'are', 'also'), ('are', 'also', 'correlated'), ('also', 'correlated', 'and'), ('correlated', 'and', 'can'), ('and', 'can', 'inflate'), ('can', 'inflate', 'the'), ('inflate', 'the', 'standard'), ('the', 'standard', 'error'), ('standard', 'error', 'of'), ('error', 'of', 'their'), ('of', 'their', 'coefficients'), ('their', 'coefficients', 'which'), ('coefficients', 'which', 'may'), ('which', 'may', 'make'), ('may', 'make', 'them'), ('make', 'them', 'seem'), ('them', 'seem', 'statistically'), ('seem', 'statistically', 'insignificant'), ('statistically', 'insignificant', '.'), ('insignificant', '.', 'To'), ('.', 'To', 'produce'), ('To', 'produce', 'a'), ('produce', 'a', 'more'), ('a', 'more', 'accurate'), ('more', 'accurate', 'model'), ('accurate', 'model', 'of'), ('model', 'of', 'complex'), ('of', 'complex', 'data'), ('complex', 'data', 'we'), ('data', 'we', 'can'), ('we', 'can', 'add'), ('can', 'add', 'a'), ('add', 'a', 'penalty'), ('a', 'penalty', 'term'), ('penalty', 'term', 'to'), ('term', 'to', 'the'), ('to', 'the', 'OLS'), ('the', 'OLS', 'equation'), ('OLS', 'equation', '.'), ('equation', '.', 'A'), ('.', 'A', 'penalty'), ('A', 'penalty', 'adds'), ('penalty', 'adds', 'a'), ('adds', 'a', 'bias'), ('a', 'bias', 'towards'), ('bias', 'towards', 'certain'), ('towards', 'certain', 'values'), ('certain', 'values', '.'), ('values', '.', 'These'), ('.', 'These', 'are'), ('These', 'are', 'known'), ('are', 'known', 'as'), ('known', 'as', 'L1'), ('as', 'L1', 'regularization'), ('L1', 'regularization', '('), ('regularization', '(', 'Lasso'), ('(', 'Lasso', 'regression'), ('Lasso', 'regression', ')'), ('regression', ')', 'and'), (')', 'and', 'L2'), ('and', 'L2', 'regularization'), ('L2', 'regularization', '('), ('regularization', '(', 'ridge'), ('(', 'ridge', 'regression'), ('ridge', 'regression', ')'), ('regression', ')', '.The'), (')', '.The', 'best'), ('.The', 'best', 'model'), ('best', 'model', 'we'), ('model', 'we', 'can'), ('we', 'can', 'hope'), ('can', 'hope', 'to'), ('hope', 'to', 'come'), ('to', 'come', 'up'), ('come', 'up', 'with'), ('up', 'with', 'minimizes'), ('with', 'minimizes', 'both'), ('minimizes', 'both', 'the'), ('both', 'the', 'bias'), ('the', 'bias', 'and'), ('bias', 'and', 'the'), ('and', 'the', 'variance'), ('the', 'variance', ':'), ('variance', ':', 'Ridge'), (':', 'Ridge', 'regression'), ('Ridge', 'regression', 'uses'), ('regression', 'uses', 'L2'), ('uses', 'L2', 'regularization'), ('L2', 'regularization', 'which'), ('regularization', 'which', 'adds'), ('which', 'adds', 'the'), ('adds', 'the', 'following'), ('the', 'following', 'penalty'), ('following', 'penalty', 'term'), ('penalty', 'term', 'to'), ('term', 'to', 'the'), ('to', 'the', 'OLS'), ('the', 'OLS', 'equation'), ('OLS', 'equation', '.'), ('equation', '.', 'L2'), ('.', 'L2', 'regularization'), ('L2', 'regularization', 'penalty'), ('regularization', 'penalty', 'term'), ('penalty', 'term', 'The'), ('term', 'The', 'L2'), ('The', 'L2', 'term'), ('L2', 'term', 'is'), ('term', 'is', 'equal'), ('is', 'equal', 'to'), ('equal', 'to', 'the'), ('to', 'the', 'square'), ('the', 'square', 'of'), ('square', 'of', 'the'), ('of', 'the', 'magnitude'), ('the', 'magnitude', 'of'), ('magnitude', 'of', 'the'), ('of', 'the', 'coefficients'), ('the', 'coefficients', '.'), ('coefficients', '.', 'In'), ('.', 'In', 'this'), ('In', 'this', 'case'), ('this', 'case', 'if'), ('case', 'if', 'lambda'), ('if', 'lambda', '('), ('lambda', '(', '?'), ('(', '?', ')'), ('?', ')', 'is'), (')', 'is', 'zero'), ('is', 'zero', 'then'), ('zero', 'then', 'the'), ('then', 'the', 'equation'), ('the', 'equation', 'is'), ('equation', 'is', 'the'), ('is', 'the', 'basic'), ('the', 'basic', 'OLS'), ('basic', 'OLS', 'but'), ('OLS', 'but', 'if'), ('but', 'if', 'it'), ('if', 'it', 'is'), ('it', 'is', 'greater'), ('is', 'greater', 'than'), ('greater', 'than', 'zero'), ('than', 'zero', 'then'), ('zero', 'then', 'we'), ('then', 'we', 'add'), ('we', 'add', 'a'), ('add', 'a', 'constraint'), ('a', 'constraint', 'to'), ('constraint', 'to', 'the'), ('to', 'the', 'coefficients'), ('the', 'coefficients', '.'), ('coefficients', '.', 'This'), ('.', 'This', 'constraint'), ('This', 'constraint', 'results'), ('constraint', 'results', 'in'), ('results', 'in', 'minimized'), ('in', 'minimized', 'coefficients'), ('minimized', 'coefficients', '('), ('coefficients', '(', 'aka'), ('(', 'aka', 'shrinkage'), ('aka', 'shrinkage', ')'), ('shrinkage', ')', 'that'), (')', 'that', 'trend'), ('that', 'trend', 'towards'), ('trend', 'towards', 'zero'), ('towards', 'zero', 'the'), ('zero', 'the', 'larger'), ('the', 'larger', 'the'), ('larger', 'the', 'value'), ('the', 'value', 'of'), ('value', 'of', 'lambda'), ('of', 'lambda', '.'), ('lambda', '.', 'Shrinking'), ('.', 'Shrinking', 'the'), ('Shrinking', 'the', 'coefficients'), ('the', 'coefficients', 'leads'), ('coefficients', 'leads', 'to'), ('leads', 'to', 'a'), ('to', 'a', 'lower'), ('a', 'lower', 'variance'), ('lower', 'variance', 'and'), ('variance', 'and', 'in'), ('and', 'in', 'turn'), ('in', 'turn', 'a'), ('turn', 'a', 'lower'), ('a', 'lower', 'error'), ('lower', 'error', 'value'), ('error', 'value', '.'), ('value', '.', 'Therefore'), ('.', 'Therefore', 'Ridge'), ('Therefore', 'Ridge', 'regression'), ('Ridge', 'regression', 'decreases'), ('regression', 'decreases', 'the'), ('decreases', 'the', 'complexity'), ('the', 'complexity', 'of'), ('complexity', 'of', 'a'), ('of', 'a', 'model'), ('a', 'model', 'but'), ('model', 'but', 'does'), ('but', 'does', 'not'), ('does', 'not', 'reduce'), ('not', 'reduce', 'the'), ('reduce', 'the', 'number'), ('the', 'number', 'of'), ('number', 'of', 'variables'), ('of', 'variables', ','), ('variables', ',', 'it'), (',', 'it', 'rather'), ('it', 'rather', 'just'), ('rather', 'just', 'shrinks'), ('just', 'shrinks', 'their'), ('shrinks', 'their', 'effect'), ('their', 'effect', '.'), ('effect', '.', 'Lasso'), ('.', 'Lasso', 'regression'), ('Lasso', 'regression', 'Lasso'), ('regression', 'Lasso', 'regression'), ('Lasso', 'regression', 'uses'), ('regression', 'uses', 'the'), ('uses', 'the', 'L1'), ('the', 'L1', 'penalty'), ('L1', 'penalty', 'term'), ('penalty', 'term', 'and'), ('term', 'and', 'stands'), ('and', 'stands', 'for'), ('stands', 'for', 'Least'), ('for', 'Least', 'Absolute'), ('Least', 'Absolute', 'Shrinkage'), ('Absolute', 'Shrinkage', 'and'), ('Shrinkage', 'and', 'Selection'), ('and', 'Selection', 'Operator'), ('Selection', 'Operator', '.'), ('Operator', '.', 'The'), ('.', 'The', 'penalty'), ('The', 'penalty', 'applied'), ('penalty', 'applied', 'for'), ('applied', 'for', 'L2'), ('for', 'L2', 'is'), ('L2', 'is', 'equal'), ('is', 'equal', 'to'), ('equal', 'to', 'the'), ('to', 'the', 'absolute'), ('the', 'absolute', 'value'), ('absolute', 'value', 'of'), ('value', 'of', 'the'), ('of', 'the', 'magnitude'), ('the', 'magnitude', 'of'), ('magnitude', 'of', 'the'), ('of', 'the', 'coefficients'), ('the', 'coefficients', ':'), ('coefficients', ':', 'L1'), (':', 'L1', 'regularization'), ('L1', 'regularization', 'penalty'), ('regularization', 'penalty', 'term'), ('penalty', 'term', 'Similar'), ('term', 'Similar', 'to'), ('Similar', 'to', 'ridge'), ('to', 'ridge', 'regression'), ('ridge', 'regression', ','), ('regression', ',', 'a'), (',', 'a', 'lambda'), ('a', 'lambda', 'value'), ('lambda', 'value', 'of'), ('value', 'of', 'zero'), ('of', 'zero', 'spits'), ('zero', 'spits', 'out'), ('spits', 'out', 'the'), ('out', 'the', 'basic'), ('the', 'basic', 'OLS'), ('basic', 'OLS', 'equation'), ('OLS', 'equation', ','), ('equation', ',', 'however'), (',', 'however', 'given'), ('however', 'given', 'a'), ('given', 'a', 'suitable'), ('a', 'suitable', 'lambda'), ('suitable', 'lambda', 'value'), ('lambda', 'value', 'lasso'), ('value', 'lasso', 'regression'), ('lasso', 'regression', 'can'), ('regression', 'can', 'drive'), ('can', 'drive', 'some'), ('drive', 'some', 'coefficients'), ('some', 'coefficients', 'to'), ('coefficients', 'to', 'zero'), ('to', 'zero', '.'), ('zero', '.', 'The'), ('.', 'The', 'larger'), ('The', 'larger', 'the'), ('larger', 'the', 'value'), ('the', 'value', 'of'), ('value', 'of', 'lambda'), ('of', 'lambda', 'the'), ('lambda', 'the', 'more'), ('the', 'more', 'features'), ('more', 'features', 'are'), ('features', 'are', 'shrunk'), ('are', 'shrunk', 'to'), ('shrunk', 'to', 'zero'), ('to', 'zero', '.'), ('zero', '.', 'This'), ('.', 'This', 'can'), ('This', 'can', 'eliminate'), ('can', 'eliminate', 'some'), ('eliminate', 'some', 'features'), ('some', 'features', 'entirely'), ('features', 'entirely', 'and'), ('entirely', 'and', 'give'), ('and', 'give', 'us'), ('give', 'us', 'a'), ('us', 'a', 'subset'), ('a', 'subset', 'of'), ('subset', 'of', 'predictors'), ('of', 'predictors', 'that'), ('predictors', 'that', 'helps'), ('that', 'helps', 'mitigate'), ('helps', 'mitigate', 'multi-collinearity'), ('mitigate', 'multi-collinearity', 'and'), ('multi-collinearity', 'and', 'model'), ('and', 'model', 'complexity'), ('model', 'complexity', '.'), ('complexity', '.', 'Predictors'), ('.', 'Predictors', 'not'), ('Predictors', 'not', 'shrunk'), ('not', 'shrunk', 'towards'), ('shrunk', 'towards', 'zero'), ('towards', 'zero', 'signify'), ('zero', 'signify', 'that'), ('signify', 'that', 'they'), ('that', 'they', 'are'), ('they', 'are', 'important'), ('are', 'important', 'and'), ('important', 'and', 'thus'), ('and', 'thus', 'L1'), ('thus', 'L1', 'regularization'), ('L1', 'regularization', 'allows'), ('regularization', 'allows', 'for'), ('allows', 'for', 'feature'), ('for', 'feature', 'selection'), ('feature', 'selection', '('), ('selection', '(', 'sparse'), ('(', 'sparse', 'selection'), ('sparse', 'selection', ')'), ('selection', ')', '.'), (')', '.', 'A'), ('.', 'A', 'third'), ('A', 'third', 'commonly'), ('third', 'commonly', 'used'), ('commonly', 'used', 'model'), ('used', 'model', 'of'), ('model', 'of', 'regression'), ('of', 'regression', 'is'), ('regression', 'is', 'the'), ('is', 'the', 'Elastic'), ('the', 'Elastic', 'Net'), ('Elastic', 'Net', 'which'), ('Net', 'which', 'incorporates'), ('which', 'incorporates', 'penalties'), ('incorporates', 'penalties', 'from'), ('penalties', 'from', 'both'), ('from', 'both', 'L1'), ('both', 'L1', 'and'), ('L1', 'and', 'L2'), ('and', 'L2', 'regularization'), ('L2', 'regularization', ':'), ('regularization', ':', 'In'), (':', 'In', 'addition'), ('In', 'addition', 'to'), ('addition', 'to', 'setting'), ('to', 'setting', 'and'), ('setting', 'and', 'choosing'), ('and', 'choosing', 'a'), ('choosing', 'a', 'lambda'), ('a', 'lambda', 'value'), ('lambda', 'value', 'elastic'), ('value', 'elastic', 'net'), ('elastic', 'net', 'also'), ('net', 'also', 'allows'), ('also', 'allows', 'us'), ('allows', 'us', 'to'), ('us', 'to', 'tune'), ('to', 'tune', 'the'), ('tune', 'the', 'alpha'), ('the', 'alpha', 'parameter'), ('alpha', 'parameter', 'where'), ('parameter', 'where', '?'), ('where', '?', '?'), ('?', '?', '='), ('?', '=', '0'), ('=', '0', 'corresponds'), ('0', 'corresponds', 'to'), ('corresponds', 'to', 'ridge'), ('to', 'ridge', 'and'), ('ridge', 'and', '?'), ('and', '?', '?'), ('?', '?', '='), ('?', '=', '1'), ('=', '1', 'to'), ('1', 'to', 'lasso'), ('to', 'lasso', '.'), ('lasso', '.', 'Simply'), ('.', 'Simply', 'put'), ('Simply', 'put', ','), ('put', ',', 'if'), (',', 'if', 'you'), ('if', 'you', 'plug'), ('you', 'plug', 'in'), ('plug', 'in', '0'), ('in', '0', 'for'), ('0', 'for', 'alpha'), ('for', 'alpha', ','), ('alpha', ',', 'the'), (',', 'the', 'penalty'), ('the', 'penalty', 'function'), ('penalty', 'function', 'reduces'), ('function', 'reduces', 'to'), ('reduces', 'to', 'the'), ('to', 'the', 'L1'), ('the', 'L1', '('), ('L1', '(', 'ridge'), ('(', 'ridge', ')'), ('ridge', ')', 'term'), (')', 'term', 'and'), ('term', 'and', 'if'), ('and', 'if', 'we'), ('if', 'we', 'set'), ('we', 'set', 'alpha'), ('set', 'alpha', 'to'), ('alpha', 'to', '1'), ('to', '1', 'we'), ('1', 'we', 'get'), ('we', 'get', 'the'), ('get', 'the', 'L2'), ('the', 'L2', '('), ('L2', '(', 'lasso'), ('(', 'lasso', ')'), ('lasso', ')', 'term'), (')', 'term', '.'), ('term', '.', 'Therefore'), ('.', 'Therefore', 'we'), ('Therefore', 'we', 'can'), ('we', 'can', 'choose'), ('can', 'choose', 'an'), ('choose', 'an', 'alpha'), ('an', 'alpha', 'value'), ('alpha', 'value', 'between'), ('value', 'between', '0'), ('between', '0', 'and'), ('0', 'and', '1'), ('and', '1', 'to'), ('1', 'to', 'optimize'), ('to', 'optimize', 'the'), ('optimize', 'the', 'elastic'), ('the', 'elastic', 'net'), ('elastic', 'net', '.'), ('net', '.', 'Effectively'), ('.', 'Effectively', 'this'), ('Effectively', 'this', 'will'), ('this', 'will', 'shrink'), ('will', 'shrink', 'some'), ('shrink', 'some', 'coefficients'), ('some', 'coefficients', 'and'), ('coefficients', 'and', 'set'), ('and', 'set', 'some'), ('set', 'some', 'to'), ('some', 'to', '0'), ('to', '0', 'for'), ('0', 'for', 'sparse'), ('for', 'sparse', 'selection'), ('sparse', 'selection', '.'), ('selection', '.', 'As'), ('.', 'As', 'we'), ('As', 'we', 'mentioned'), ('we', 'mentioned', 'in'), ('mentioned', 'in', 'the'), ('in', 'the', 'previous'), ('the', 'previous', 'sections'), ('previous', 'sections', ','), ('sections', ',', 'lambda'), (',', 'lambda', 'values'), ('lambda', 'values', 'have'), ('values', 'have', 'a'), ('have', 'a', 'large'), ('a', 'large', 'effect'), ('large', 'effect', 'on'), ('effect', 'on', 'coefficients'), ('on', 'coefficients', 'so'), ('coefficients', 'so', 'now'), ('so', 'now', 'we'), ('now', 'we', 'will'), ('we', 'will', 'compute'), ('will', 'compute', 'and'), ('compute', 'and', 'chose'), ('and', 'chose', 'a'), ('chose', 'a', 'suitable'), ('a', 'suitable', 'one'), ('suitable', 'one', '.'), ('one', '.', 'Here'), ('.', 'Here', 'we'), ('Here', 'we', 'perform'), ('we', 'perform', 'a'), ('perform', 'a', 'cross'), ('a', 'cross', 'validation'), ('cross', 'validation', 'and'), ('validation', 'and', 'take'), ('and', 'take', 'a'), ('take', 'a', 'peek'), ('a', 'peek', 'at'), ('peek', 'at', 'the'), ('at', 'the', 'lambda'), ('the', 'lambda', 'value'), ('lambda', 'value', 'corresponding'), ('value', 'corresponding', 'to'), ('corresponding', 'to', 'the'), ('to', 'the', 'lowest'), ('the', 'lowest', 'prediction'), ('lowest', 'prediction', 'error'), ('prediction', 'error', 'before'), ('error', 'before', 'fitting'), ('before', 'fitting', 'the'), ('fitting', 'the', 'data'), ('the', 'data', 'to'), ('data', 'to', 'the'), ('to', 'the', 'model'), ('the', 'model', 'and'), ('model', 'and', 'viewing'), ('and', 'viewing', 'the'), ('viewing', 'the', 'coefficients'), ('the', 'coefficients', '.'), ('coefficients', '.', 'We'), ('.', 'We', 'can'), ('We', 'can', 'see'), ('can', 'see', 'here'), ('see', 'here', 'that'), ('here', 'that', 'certain'), ('that', 'certain', 'coefficients'), ('certain', 'coefficients', 'have'), ('coefficients', 'have', 'been'), ('have', 'been', 'pushed'), ('been', 'pushed', 'towards'), ('pushed', 'towards', 'zero'), ('towards', 'zero', 'and'), ('zero', 'and', 'minimized'), ('and', 'minimized', 'while'), ('minimized', 'while', 'RM'), ('while', 'RM', '('), ('RM', '(', 'number'), ('(', 'number', 'of'), ('number', 'of', 'rooms'), ('of', 'rooms', ')'), ('rooms', ')', 'has'), (')', 'has', 'a'), ('has', 'a', 'significantly'), ('a', 'significantly', 'higher'), ('significantly', 'higher', 'weight'), ('higher', 'weight', 'than'), ('weight', 'than', 'the'), ('than', 'the', 'rest'), ('the', 'rest', 'Performing'), ('rest', 'Performing', 'Lasso'), ('Performing', 'Lasso', 'regression'), ('Lasso', 'regression', 'The'), ('regression', 'The', 'steps'), ('The', 'steps', 'will'), ('steps', 'will', 'be'), ('will', 'be', 'identical'), ('be', 'identical', 'to'), ('identical', 'to', 'what'), ('to', 'what', 'we'), ('what', 'we', 'have'), ('we', 'have', 'done'), ('have', 'done', 'for'), ('done', 'for', 'ridge'), ('for', 'ridge', 'regression'), ('ridge', 'regression', '.'), ('regression', '.', 'The'), ('.', 'The', 'value'), ('The', 'value', 'of'), ('value', 'of', 'alpha'), ('of', 'alpha', 'is'), ('alpha', 'is', 'the'), ('is', 'the', 'only'), ('the', 'only', 'change'), ('only', 'change', 'here'), ('change', 'here', '('), ('here', '(', 'remember'), ('(', 'remember', '?'), ('remember', '?', '?'), ('?', '?', '='), ('?', '=', '1'), ('=', '1', 'denotes'), ('1', 'denotes', 'lasso'), ('denotes', 'lasso', ')'), ('lasso', ')', 'Performing'), (')', 'Performing', 'Elastic'), ('Performing', 'Elastic', 'Net'), ('Elastic', 'Net', 'regression'), ('Net', 'regression', 'Performing'), ('regression', 'Performing', 'Elastic'), ('Performing', 'Elastic', 'Net'), ('Elastic', 'Net', 'requires'), ('Net', 'requires', 'us'), ('requires', 'us', 'to'), ('us', 'to', 'tune'), ('to', 'tune', 'parameters'), ('tune', 'parameters', 'to'), ('parameters', 'to', 'identify'), ('to', 'identify', 'the'), ('identify', 'the', 'best'), ('the', 'best', 'alpha'), ('best', 'alpha', 'and'), ('alpha', 'and', 'lambda'), ('and', 'lambda', 'values'), ('lambda', 'values', 'and'), ('values', 'and', 'for'), ('and', 'for', 'this'), ('for', 'this', 'we'), ('this', 'we', 'need'), ('we', 'need', 'to'), ('need', 'to', 'use'), ('to', 'use', 'the'), ('use', 'the', 'caret'), ('the', 'caret', 'package'), ('caret', 'package', '.'), ('package', '.', 'We'), ('.', 'We', 'will'), ('We', 'will', 'tune'), ('will', 'tune', 'the'), ('tune', 'the', 'model'), ('the', 'model', 'by'), ('model', 'by', 'iterating'), ('by', 'iterating', 'over'), ('iterating', 'over', 'a'), ('over', 'a', 'number'), ('a', 'number', 'of'), ('number', 'of', 'alpha'), ('of', 'alpha', 'and'), ('alpha', 'and', 'lambda'), ('and', 'lambda', 'pairs'), ('lambda', 'pairs', 'and'), ('pairs', 'and', 'we'), ('and', 'we', 'can'), ('we', 'can', 'see'), ('can', 'see', 'which'), ('see', 'which', 'pair'), ('which', 'pair', 'has'), ('pair', 'has', 'the'), ('has', 'the', 'lowest'), ('the', 'lowest', 'associated'), ('lowest', 'associated', 'error'), ('associated', 'error', '.'), ('error', '.', 'We'), ('.', 'We', 'can'), ('We', 'can', 'see'), ('can', 'see', 'that'), ('see', 'that', 'the'), ('that', 'the', 'R'), ('the', 'R', 'mean-squared'), ('R', 'mean-squared', 'values'), ('mean-squared', 'values', 'using'), ('values', 'using', 'all'), ('using', 'all', 'three'), ('all', 'three', 'models'), ('three', 'models', 'were'), ('models', 'were', 'very'), ('were', 'very', 'close'), ('very', 'close', 'to'), ('close', 'to', 'each'), ('to', 'each', 'other'), ('each', 'other', ','), ('other', ',', 'but'), (',', 'but', 'both'), ('but', 'both', 'did'), ('both', 'did', 'marginally'), ('did', 'marginally', 'perform'), ('marginally', 'perform', 'better'), ('perform', 'better', 'than'), ('better', 'than', 'ridge'), ('than', 'ridge', 'regression'), ('ridge', 'regression', '('), ('regression', '(', 'Lasso'), ('(', 'Lasso', 'having'), ('Lasso', 'having', 'done'), ('having', 'done', 'best'), ('done', 'best', ')'), ('best', ')', '.'), (')', '.', 'Lasso'), ('.', 'Lasso', 'regression'), ('Lasso', 'regression', 'also'), ('regression', 'also', 'showed'), ('also', 'showed', 'the'), ('showed', 'the', 'highest'), ('the', 'highest', 'R'), ('highest', 'R', 'value'), ('R', 'value', '.')]\n"
     ]
    }
   ],
   "source": [
    "#c. To Find all the trigrams for the words.\n",
    "from nltk import trigrams\n",
    "Q7_trigrams = list(trigrams(q7wordToken))\n",
    "\n",
    "print(Q7_trigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(('we', 'need', 'to'), 3), (('the', 'coefficients', '.'), 3), (('?', '?', '='), 3), (('to', 'find', 'the'), 2), (('find', 'the', 'optimal'), 2), (('over', 'a', 'number'), 2), (('a', 'number', 'of'), 2), (('to', 'each', 'other'), 2), (('penalty', 'term', 'to'), 2), (('term', 'to', 'the'), 2)])\n"
     ]
    }
   ],
   "source": [
    "#d. To Extract the top 10 of the most repeated trigrams based on their count\n",
    "from collections import Counter, OrderedDict\n",
    "import operator\n",
    "\n",
    "q7_repeated_trigrams = Counter(Q7_trigrams).most_common(10)\n",
    "\n",
    "repeated_trigrams = OrderedDict(q7_repeated_trigrams)\n",
    "\n",
    "print(repeated_trigrams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First we need to understand the basics of regression and what parameters of the equation are changed when using a specific model.->repeated tri-grams:(we need to )\n",
      "Visualization of the squared error (from Setosa.io)\n",
      "The equation for this model is referred to as the cost function and is a way to find the optimal error by minimizing and measuring it.->repeated tri-grams:(to find the )\n",
      "Visualization of the squared error (from Setosa.io)\n",
      "The equation for this model is referred to as the cost function and is a way to find the optimal error by minimizing and measuring it.->repeated tri-grams:(find the optimal )\n",
      "The gradient descent algorithm is used to find the optimal cost function by going over a number of iterations.->repeated tri-grams:(to find the )\n",
      "The gradient descent algorithm is used to find the optimal cost function by going over a number of iterations.->repeated tri-grams:(find the optimal )\n",
      "The gradient descent algorithm is used to find the optimal cost function by going over a number of iterations.->repeated tri-grams:(over a number )\n",
      "The gradient descent algorithm is used to find the optimal cost function by going over a number of iterations.->repeated tri-grams:(a number of )\n",
      "But the data we need to define and analyze is not always so easy to characterize with the base OLS model.->repeated tri-grams:(we need to )\n",
      "Equation for least ordinary squares\n",
      "One situation is the data showing multi-collinearity, this is when predictor variables are correlated to each other and to the response variable.->repeated tri-grams:(to each other )\n",
      "To produce a more accurate model of complex data we can add a penalty term to the OLS equation.->repeated tri-grams:(penalty term to )\n",
      "To produce a more accurate model of complex data we can add a penalty term to the OLS equation.->repeated tri-grams:(term to the )\n",
      "These are known as L1 regularization(Lasso regression) and L2 regularization(ridge regression).The best model we can hope to come up with minimizes both the bias and the variance:\n",
      "Ridge regression uses L2 regularization which adds the following penalty term to the OLS equation.->repeated tri-grams:(penalty term to )\n",
      "These are known as L1 regularization(Lasso regression) and L2 regularization(ridge regression).The best model we can hope to come up with minimizes both the bias and the variance:\n",
      "Ridge regression uses L2 regularization which adds the following penalty term to the OLS equation.->repeated tri-grams:(term to the )\n",
      "= 1 denotes lasso)\n",
      "Performing Elastic Net regression\n",
      "Performing Elastic Net requires us to tune parameters to identify the best alpha and lambda values and for this we need to use the caret package.->repeated tri-grams:(we need to )\n",
      "We will tune the model by iterating over a number of alpha and lambda pairs and we can see which pair has the lowest associated error.->repeated tri-grams:(over a number )\n",
      "We will tune the model by iterating over a number of alpha and lambda pairs and we can see which pair has the lowest associated error.->repeated tri-grams:(a number of )\n"
     ]
    }
   ],
   "source": [
    "#F. To Find all the sentences with the most repeated tri-grams\n",
    "q7sentenceToken = nltk.sent_tokenize(nlp_q7_text)\n",
    "\n",
    "myList = []\n",
    "result = []\n",
    "for w in repeated_trigrams:\n",
    "    for word in w:\n",
    "        \n",
    "        mystring += word\n",
    "        mystring += ' '\n",
    "    myList.append(mystring)\n",
    "    mystring = ''\n",
    "\n",
    "\n",
    "for sentence in q7sentenceToken:\n",
    "    for l in myList:\n",
    "        if l in sentence:\n",
    "            stringResult=''\n",
    "            stringResult += sentence +'->repeated tri-grams:('+l+')'\n",
    "            result.append(stringResult)\n",
    "for r in result:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
